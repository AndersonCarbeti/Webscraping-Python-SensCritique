{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eaba437",
   "metadata": {},
   "source": [
    "# Scrapping User rated movie collection from \"Senscritique\" using Selenium and BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef216f32",
   "metadata": {},
   "source": [
    "## Aims, objectives and background\n",
    "    \n",
    "### Objectif: The project aims to collect data on movies of a user from the popular film website SensCritique.\n",
    "#### The collected data will be exported in an csv file.\n",
    "\n",
    "#### SensCritique is a French website dedicated to the culture of cinema, series, music, and books, it allows users to rate, review, and create collections of the media they've seen, read, and listen.\n",
    "\n",
    "#### The website will be accessed using the Python programming language, the Selenium library and the Beautiful Soup library will be utilized to automate the process of navigating the website and extracting the relevant information.\n",
    "#### The collected data will be futher analyzed to gain insights and make informed decisions.\n",
    "\n",
    "#### ðŸ‘‡ Code below ðŸ‘‡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b1ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librairies\n",
    "import csv\n",
    "import time\n",
    "import selenium\n",
    "import bs4\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BeautifulSoup    \n",
    "# Configuration du pilote web\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.senscritique.com/Wanderson/collection')\n",
    "\n",
    "# Identifie, click sur \"AcceptÃ© les cookies\", \"NotÃ©\" et \"Films\" puis attend 15 secondes entre chaques clicks\n",
    "wait_time = 15\n",
    "button_xpath = [\n",
    "    '//button[@id=\"didomi-notice-agree-button\"]',\n",
    "    '//*[@id=\"__next\"]/div[1]/div/main/div[2]/div/div[1]/div[2]/div[2]/p[6]',\n",
    "    '//*[@id=\"__next\"]/div[1]/div/main/div[2]/div/div[1]/div[3]/div[2]/p[2]'\n",
    "]\n",
    "\n",
    "for path in button_xpath:\n",
    "    time.sleep(wait_time)\n",
    "    try:\n",
    "        button = driver.find_element(By.XPATH, path)\n",
    "        button.click()\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "\n",
    "# Initialize a list to store the data\n",
    "data = []\n",
    "\n",
    "# Loop through pages 1 to 5\n",
    "for loop_counter in range(1, 6):\n",
    "    # Find the page number element and click on it\n",
    "    xpath = '//*[@id=\"__next\"]/div[1]/div/main/div[2]/div/div[2]/div/div[2]/nav/span[' + str(loop_counter) + ']'\n",
    "    element = driver.find_element(By.XPATH, xpath)\n",
    "    element.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    elements = soup.select('.Rating__ActivityRating-sc-1rkvzid-4[data-testid=\"Rating\"]')\n",
    "    ratings = [element.text for element in elements]\n",
    "    elements_a = driver.find_elements(By.TAG_NAME, 'a')\n",
    "\n",
    "    # Add the element texts to the data list\n",
    "    for element in elements_a:\n",
    "        data.append([element.text])\n",
    "    for rating in ratings:\n",
    "        data.append([rating])\n",
    "\n",
    "\n",
    "# Prompt user for number of pages to scrape next\n",
    "no_of_pages = int(input('Enter the #pages to scrape: ')) - 5\n",
    "\n",
    "# Loop through the remaining pages\n",
    "for i in range(no_of_pages):\n",
    "    # Find the \"next\" button and click on it\n",
    "    button = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div[1]/div/main/div[2]/div/div[2]/div/div[2]/nav/span[6]')\n",
    "    button.click()\n",
    "\n",
    "    # Wait for 2 seconds for the page to load\n",
    "    time.sleep(2)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    elements = soup.select('.Rating__ActivityRating-sc-1rkvzid-4[data-testid=\"Rating\"]')\n",
    "    ratings = [element.text for element in elements]\n",
    "    elements_a = driver.find_elements(By.TAG_NAME, 'a')\n",
    "\n",
    "    # Add the element texts to the data list\n",
    "    for element in elements_a:\n",
    "        data.append([element.text])\n",
    "    for rating in ratings:\n",
    "        data.append([rating])\n",
    "\n",
    "# Create a new CSV file\n",
    "with open('scraped_data.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # Write the data to the CSV file\n",
    "    for row in data:\n",
    "        writer.writerow(row)\n",
    "        \n",
    "    # Close the browser\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca87d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find end button and click on it\n",
    "buttonend = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div[1]/div/main/div[2]/div/div[2]/div/div[2]/nav/span[8]')\n",
    "buttonend.click()\n",
    "\n",
    "time.sleep(2)\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "elements = soup.select('.Rating__ActivityRating-sc-1rkvzid-4[data-testid=\"Rating\"]')\n",
    "ratings = [element.text for element in elements]\n",
    "elements_a = driver.find_elements(By.TAG_NAME, 'a')\n",
    "     # Close the browser\n",
    "driver.quit()\n"
   ]
  },
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
